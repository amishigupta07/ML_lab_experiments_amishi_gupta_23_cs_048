{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K3Yby9KFEPKH"
      },
      "source": [
        "**Experiment 9 : Implementing a\n",
        "Neural Network and\n",
        "Backpropagation from Scratch**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nqkjAlJiEPEa"
      },
      "source": [
        "Name : Amishi Gupta"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1wUVwUmEO47"
      },
      "source": [
        "Roll No. 23/CS/048"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "B6a19_5gELOe"
      },
      "outputs": [],
      "source": [
        "#Import all necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.neural_network import MLPClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2-dy1t_uEkQH",
        "outputId": "1bf0e6f2-6b0a-4215-f62a-0b096a31077e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X (Features) Shape: (569, 30)\n",
            "y (Target) Shape: (569,)\n",
            "\n",
            "Feature Names:\n",
            "['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n",
            " 'mean smoothness' 'mean compactness' 'mean concavity'\n",
            " 'mean concave points' 'mean symmetry' 'mean fractal dimension'\n",
            " 'radius error' 'texture error' 'perimeter error' 'area error'\n",
            " 'smoothness error' 'compactness error' 'concavity error'\n",
            " 'concave points error' 'symmetry error' 'fractal dimension error'\n",
            " 'worst radius' 'worst texture' 'worst perimeter' 'worst area'\n",
            " 'worst smoothness' 'worst compactness' 'worst concavity'\n",
            " 'worst concave points' 'worst symmetry' 'worst fractal dimension']\n",
            "\n",
            "Target Classes: ['malignant' 'benign']\n",
            "\n",
            "Training samples: 398\n",
            "Validation samples: 171\n",
            "\n",
            "Data preprocessing complete\n"
          ]
        }
      ],
      "source": [
        "#Load Data\n",
        "data= load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "#Inspect Data\n",
        "print(f\"X (Features) Shape: {X.shape}\")\n",
        "print(f\"y (Target) Shape: {y.shape}\")\n",
        "print(\"\\nFeature Names:\")\n",
        "print(data.feature_names)\n",
        "print(f\"\\nTarget Classes: {data.target_names}\")\n",
        "\n",
        "#(70/30 split)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "print(f\"\\nTraining samples: {X_train.shape[0]}\")\n",
        "print(f\"Validation samples: {X_val.shape[0]}\")\n",
        "\n",
        "#Standardize Features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "X_val_scaled = scaler.transform(X_val)\n",
        "\n",
        "print(\"\\nData preprocessing complete\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-Gwy_5QEyFv",
        "outputId": "5db99643-64e0-4390-8ec8-61d33c2a4676"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Utility functions defined\n"
          ]
        }
      ],
      "source": [
        "#Activation Functions\n",
        "def sigmoid(Z):\n",
        "    return 1 / (1 + np.exp(-Z))\n",
        "\n",
        "def relu(Z):\n",
        "    return np.maximum(0, Z)\n",
        "\n",
        "#Activation Derivatives\n",
        "def sigmoid_derivative(A):\n",
        "    return A * (1 - A)\n",
        "\n",
        "def relu_derivative(Z):\n",
        "    #Returns 1 if Z > 0, 0 otherwise\n",
        "    return (Z > 0) * 1\n",
        "\n",
        "#Loss Functions\n",
        "def compute_bce_loss(Y, Y_hat):\n",
        "    m = Y.shape[1]\n",
        "    epsilon = 1e-15\n",
        "    cost = -1/m * np.sum(Y*np.log(Y_hat + epsilon) + (1 - Y) * np.log(1 - Y_hat + epsilon))\n",
        "    return np.squeeze(cost)\n",
        "\n",
        "def compute_mse_loss(Y, Y_hat):\n",
        "    m = Y.shape[1]\n",
        "    cost = 1/m * np.sum((Y_hat - Y)**2)\n",
        "    return np.squeeze(cost)\n",
        "\n",
        "print(\"Utility functions defined\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IBZM28ZYEyDq",
        "outputId": "f682847c-c80e-4cc3-e780-15b775b6a21d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MyANNClassifier class defined\n"
          ]
        }
      ],
      "source": [
        "class MyANNClassifier:\n",
        "    def __init__(self, layer_dims, learning_rate=0.01, n_iterations=1000, loss='bce'):\n",
        "        self.layer_dims = layer_dims\n",
        "        self.learning_rate = learning_rate\n",
        "        self.n_iterations = n_iterations\n",
        "        self.loss = loss\n",
        "        self.parameters_ = {}\n",
        "        self.costs_ = []\n",
        "        self.grads_ = {}\n",
        "\n",
        "    def _initialize_parameters(self):\n",
        "        np.random.seed(42)\n",
        "        L = len(self.layer_dims)\n",
        "        for l in range(1, L):\n",
        "            self.parameters_['W' + str(l)] = np.random.randn(self.layer_dims[l], self.layer_dims[l-1]) * 0.01\n",
        "            self.parameters_['b' + str(l)] = np.zeros((self.layer_dims[l], 1))\n",
        "\n",
        "    def _forward_propagation(self, X):\n",
        "        cache = []\n",
        "        A = X\n",
        "        L = len(self.parameters_) // 2\n",
        "        for l in range(1, L):\n",
        "            A_prev = A\n",
        "            W = self.parameters_['W' + str(l)]\n",
        "            b = self.parameters_['b' + str(l)]\n",
        "            Z = np.dot(W, A_prev) + b\n",
        "            A = relu(Z)\n",
        "\n",
        "            linear_cache = (A_prev, W, b)\n",
        "            activation_cache = Z\n",
        "            cache.append((linear_cache, activation_cache))\n",
        "\n",
        "        A_prev = A\n",
        "        W = self.parameters_['W' + str(L)]\n",
        "        b = self.parameters_['b' + str(L)]\n",
        "\n",
        "        Z = np.dot(W, A_prev) + b\n",
        "        A_L = sigmoid(Z)\n",
        "\n",
        "        linear_cache = (A_prev, W, b)\n",
        "        activation_cache = Z\n",
        "        cache.append((linear_cache, activation_cache))\n",
        "\n",
        "        return A_L, cache\n",
        "\n",
        "    def _backward_propagation(self, Y, Y_hat, cache):\n",
        "        self.grads_ = {}\n",
        "        L = len(self.parameters_) // 2\n",
        "        m = Y.shape[1]\n",
        "        Y = Y.reshape(Y_hat.shape)\n",
        "\n",
        "        if self.loss == 'bce':\n",
        "            dA_L = -(np.divide(Y, Y_hat + 1e-15) - np.divide(1 - Y, 1 - Y_hat + 1e-15))\n",
        "        elif self.loss == 'mse':\n",
        "            dA_L = 2 * (Y_hat - Y)\n",
        "\n",
        "        linear_cache_L, Z_L = cache[L-1]\n",
        "        A_prev_L, W_L, b_L = linear_cache_L\n",
        "\n",
        "        dZ_L = dA_L * sigmoid_derivative(Y_hat)\n",
        "\n",
        "        self.grads_['dW' + str(L)] = (1/m) * np.dot(dZ_L, A_prev_L.T)\n",
        "        self.grads_['db' + str(L)] = (1/m) * np.sum(dZ_L, axis=1, keepdims=True)\n",
        "        dA_prev = np.dot(W_L.T, dZ_L)\n",
        "\n",
        "        for l in reversed(range(L-1)):\n",
        "            linear_cache, Z = cache[l]\n",
        "            A_prev, W, b = linear_cache\n",
        "\n",
        "            dZ = dA_prev * relu_derivative(Z)\n",
        "\n",
        "            self.grads_['dW' + str(l+1)] = (1/m) * np.dot(dZ, A_prev.T)\n",
        "            self.grads_['db' + str(l+1)] = (1/m) * np.sum(dZ, axis=1, keepdims=True)\n",
        "            dA_prev = np.dot(W.T, dZ)\n",
        "\n",
        "    def _update_parameters(self):\n",
        "        L = len(self.parameters_) // 2\n",
        "\n",
        "        for l in range(1, L + 1):\n",
        "            self.parameters_['W' + str(l)] = self.parameters_['W' + str(l)] - self.learning_rate * self.grads_['dW' + str(l)]\n",
        "            self.parameters_['b' + str(l)] = self.parameters_['b' + str(l)] - self.learning_rate * self.grads_['db' + str(l)]\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        # Reshape X\n",
        "        X_fit = X.T\n",
        "        # Reshape y\n",
        "        y_fit = y.reshape(1, -1)\n",
        "\n",
        "        if X_fit.shape[0] != self.layer_dims[0]:\n",
        "            raise ValueError(f\"Input feature count ({X_fit.shape[0]}) does not match layer_dims[0] ({self.layer_dims[0]})\")\n",
        "\n",
        "        #Initialize parameters\n",
        "        self._initialize_parameters()\n",
        "        self.costs_ = [] #Reset costs\n",
        "\n",
        "        print(f\"Starting training for {self.n_iterations} iterations with {self.loss.upper()} loss...\")\n",
        "\n",
        "        #Gradient Descent Loop\n",
        "        for i in range(self.n_iterations):\n",
        "            #Forward propagation\n",
        "            Y_hat, cache = self._forward_propagation(X_fit)\n",
        "\n",
        "            #Compute loss\n",
        "            if self.loss == 'bce':\n",
        "                cost = compute_bce_loss(y_fit, Y_hat)\n",
        "            elif self.loss == 'mse':\n",
        "                cost = compute_mse_loss(y_fit, Y_hat)\n",
        "\n",
        "            #Backward propagation\n",
        "            self._backward_propagation(y_fit, Y_hat, cache)\n",
        "\n",
        "            #Update parameters\n",
        "            self._update_parameters()\n",
        "\n",
        "            #Store cost every 100 iterations\n",
        "            if i % 100 == 0:\n",
        "                self.costs_.append(cost)\n",
        "                if i % 1000 == 0:\n",
        "                    print(f\"Cost after iteration {i}: {cost:.6f}\")\n",
        "\n",
        "        print(f\"Training complete. Final cost: {cost:.6f}\")\n",
        "\n",
        "    def predict(self, X):\n",
        "        # Reshape X\n",
        "        X_pred = X.T\n",
        "\n",
        "        #Run forward propagation\n",
        "        Y_hat, _ = self._forward_propagation(X_pred)\n",
        "\n",
        "        #Convert probabilities to binary predictions\n",
        "        predictions = (Y_hat > 0.5).astype(int)\n",
        "\n",
        "        #Return as a flattened 1D array\n",
        "        return predictions.flatten()\n",
        "\n",
        "print(\"MyANNClassifier class defined\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9zkF1VMsEyBV",
        "outputId": "ae29a51f-1d10-49cf-b996-d64574f9bf65"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training Model 1: [30, 10, 1] with BCE Loss\n",
            "Starting training for 5000 iterations with BCE loss...\n",
            "Cost after iteration 0: 0.693180\n",
            "Cost after iteration 1000: 0.680122\n",
            "Cost after iteration 2000: 0.670488\n",
            "Cost after iteration 3000: 0.657429\n",
            "Cost after iteration 4000: 0.621066\n",
            "Training complete. Final cost: 0.519979\n",
            "\n",
            "Model 1 Evaluation (BCE, 1 Hidden Layer)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.65      0.79        63\n",
            "           1       0.83      1.00      0.91       108\n",
            "\n",
            "    accuracy                           0.87       171\n",
            "   macro avg       0.92      0.83      0.85       171\n",
            "weighted avg       0.89      0.87      0.86       171\n",
            "\n",
            "\n",
            "Training Model 2: [30, 10, 1] with MSE Loss\n",
            "Starting training for 5000 iterations with MSE loss...\n",
            "Cost after iteration 0: 0.250016\n",
            "Cost after iteration 1000: 0.246399\n",
            "Cost after iteration 2000: 0.243501\n",
            "Cost after iteration 3000: 0.241054\n",
            "Cost after iteration 4000: 0.238751\n",
            "Training complete. Final cost: 0.236155\n",
            "\n",
            "Model 2 Evaluation (MSE, 1 Hidden Layer)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        63\n",
            "           1       0.63      1.00      0.77       108\n",
            "\n",
            "    accuracy                           0.63       171\n",
            "   macro avg       0.32      0.50      0.39       171\n",
            "weighted avg       0.40      0.63      0.49       171\n",
            "\n",
            "\n",
            "Training Model 3: [30, 10, 5, 1] with BCE Loss\n",
            "Starting training for 5000 iterations with BCE loss...\n",
            "Cost after iteration 0: 0.693145\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cost after iteration 1000: 0.680719\n",
            "Cost after iteration 2000: 0.673173\n",
            "Cost after iteration 3000: 0.668575\n",
            "Cost after iteration 4000: 0.665762\n",
            "Training complete. Final cost: 0.664037\n",
            "\n",
            "Model 3 Evaluation (BCE, 2 Hidden Layers)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        63\n",
            "           1       0.63      1.00      0.77       108\n",
            "\n",
            "    accuracy                           0.63       171\n",
            "   macro avg       0.32      0.50      0.39       171\n",
            "weighted avg       0.40      0.63      0.49       171\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "n_features = X_train_scaled.shape[1]\n",
        "\n",
        "print(\"\\nTraining Model 1: [30, 10, 1] with BCE Loss\")\n",
        "layer_dims_1 = [n_features, 10, 1]\n",
        "model_1 = MyANNClassifier(layer_dims_1, learning_rate=0.001, n_iterations=5000, loss='bce')\n",
        "model_1.fit(X_train_scaled, y_train)\n",
        "\n",
        "y_pred_1 = model_1.predict(X_val_scaled)\n",
        "print(\"\\nModel 1 Evaluation (BCE, 1 Hidden Layer)\")\n",
        "print(classification_report(y_val, y_pred_1))\n",
        "\n",
        "print(\"\\nTraining Model 2: [30, 10, 1] with MSE Loss\")\n",
        "layer_dims_2 = [n_features, 10, 1]\n",
        "model_2 = MyANNClassifier(layer_dims_2, learning_rate=0.001, n_iterations=5000, loss='mse')\n",
        "model_2.fit(X_train_scaled, y_train)\n",
        "\n",
        "y_pred_2 = model_2.predict(X_val_scaled)\n",
        "print(\"\\nModel 2 Evaluation (MSE, 1 Hidden Layer)\")\n",
        "print(classification_report(y_val, y_pred_2))\n",
        "\n",
        "print(\"\\nTraining Model 3: [30, 10, 5, 1] with BCE Loss\")\n",
        "layer_dims_3 = [n_features, 10, 5, 1]\n",
        "model_3 = MyANNClassifier(layer_dims_3, learning_rate=0.001, n_iterations=5000, loss='bce')\n",
        "model_3.fit(X_train_scaled, y_train)\n",
        "\n",
        "y_pred_3 = model_3.predict(X_val_scaled)\n",
        "print(\"\\nModel 3 Evaluation (BCE, 2 Hidden Layers)\")\n",
        "print(classification_report(y_val, y_pred_3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F0YZ-dAVGZzU",
        "outputId": "0ee27aa0-071a-4c82-80c6-d165e9908ad5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training Model 4: sklearn.MLPClassifier\n",
            "\n",
            "Model 4 Evaluation (sklearn.MLPClassifier)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.98      0.98        63\n",
            "           1       0.99      0.99      0.99       108\n",
            "\n",
            "    accuracy                           0.99       171\n",
            "   macro avg       0.99      0.99      0.99       171\n",
            "weighted avg       0.99      0.99      0.99       171\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nTraining Model 4: sklearn.MLPClassifier\")\n",
        "model_4 = MLPClassifier(hidden_layer_sizes=(10,),\n",
        "                        activation='relu',\n",
        "                        solver='adam',\n",
        "                        max_iter=1000,\n",
        "                        learning_rate_init=0.001,\n",
        "                        random_state=42)\n",
        "\n",
        "model_4.fit(X_train_scaled, y_train)\n",
        "\n",
        "y_pred_4 = model_4.predict(X_val_scaled)\n",
        "print(\"\\nModel 4 Evaluation (sklearn.MLPClassifier)\")\n",
        "print(classification_report(y_val, y_pred_4))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
