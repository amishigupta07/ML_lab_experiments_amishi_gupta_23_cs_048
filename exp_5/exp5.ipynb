{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GWU_jDOLuImY"
      },
      "source": [
        "**Experiment-5: Decision Trees from Scratch**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IScDypMS_G-r"
      },
      "source": [
        "Name : Amishi Gupta"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55oJAil__G2E"
      },
      "source": [
        "Roll No. : 23/CS/048"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BdUvsmaQ_53B",
        "outputId": "b824f12f-f252-42d8-a7e4-ddafe3fc695c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: ucimlrepo in /usr/local/lib/python3.12/dist-packages (0.0.7)\n",
            "Requirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from ucimlrepo) (2.2.2)\n",
            "Requirement already satisfied: certifi>=2020.12.5 in /usr/local/lib/python3.12/dist-packages (from ucimlrepo) (2025.10.5)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.0->ucimlrepo) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.0->ucimlrepo) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.0->ucimlrepo) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.0->ucimlrepo) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->ucimlrepo) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install ucimlrepo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "AnH2EfPuuHnr"
      },
      "outputs": [],
      "source": [
        "#imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from ucimlrepo import fetch_ucirepo\n",
        "from collections import Counter\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\n",
        "from sklearn.tree import DecisionTreeClassifier as SklearnDecisionTree\n",
        "import copy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TzGNFf5RAbLG"
      },
      "source": [
        "1. Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "CMqvBKIgAB0i"
      },
      "outputs": [],
      "source": [
        "#Fetch dataset\n",
        "try:\n",
        "    adult = fetch_ucirepo(id=2)\n",
        "    X_df = adult.data.features\n",
        "    y_df = adult.data.targets\n",
        "except Exception as e:\n",
        "    print(f\"Could not fetch data from ucimlrepo. Error:{e}\")\n",
        "    exit()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "h63wh2ECABuz"
      },
      "outputs": [],
      "source": [
        "# combine features and target\n",
        "df = pd.concat([X_df,y_df],axis=1)\n",
        "df.replace('?', np.nan,inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EZF0qkQAABsN",
        "outputId": "a3a76665-8320-4a3d-c530-efaf4e93d972"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dataset shape after dropping missing values: (45222, 15)\n"
          ]
        }
      ],
      "source": [
        "# handling missing values\n",
        "df.dropna(inplace=True)\n",
        "print(f\"dataset shape after dropping missing values: {df.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "h19qr_JaABl-"
      },
      "outputs": [],
      "source": [
        "# separate features and target\n",
        "X = df.drop('income',axis=1)\n",
        "y = df['income']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "5DQRu2uoABAQ"
      },
      "outputs": [],
      "source": [
        "# encode categorical features\n",
        "categorical_cols=X.select_dtypes(include=['object']).columns\n",
        "for col in categorical_cols:\n",
        "    le =LabelEncoder()\n",
        "    X[col] =le.fit_transform(X[col])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "v0CQ0I4fB5m4"
      },
      "outputs": [],
      "source": [
        "#<=50K becomes 0,>50K becomes 1\n",
        "y = y.apply(lambda x: 1 if x in ['>50K', '>50K.'] else 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "aI5Vi25kB9yV"
      },
      "outputs": [],
      "source": [
        "X_np = X.to_numpy()\n",
        "y_np = y.to_numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "VSeqoNw7CBVa"
      },
      "outputs": [],
      "source": [
        "# split the dataset\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X_np, y_np, test_size=0.4, random_state=42, stratify=y_np)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TKjegGBwCUv3",
        "outputId": "87660487-be46-4d8f-b19e-0e56f3c7d4fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training set size:27133\n",
            "Validation set size:9044\n",
            "Test set size:9045\n"
          ]
        }
      ],
      "source": [
        "#checking\n",
        "print(f\"Training set size:{len(X_train)}\")\n",
        "print(f\"Validation set size:{len(X_val)}\")\n",
        "print(f\"Test set size:{len(X_test)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rALloOvECagE"
      },
      "source": [
        "2. Build a Decision Tree From Scratch and pre prunnung"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "2WM3AtZFDC80"
      },
      "outputs": [],
      "source": [
        "#node\n",
        "class Node:\n",
        "    def __init__(self, feature_index=None,threshold=None,left=None,right=None,*,value=None,impurity=None):\n",
        "        self.feature_index =feature_index\n",
        "        self.threshold =threshold\n",
        "        self.left =left\n",
        "        self.right =right\n",
        "        self.value= value\n",
        "        self.impurity= impurity\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u_cqpSMiJXMo",
        "outputId": "654276fd-c884-49e1-da6d-30669e746cf7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Decision Tree Implementation Defined\n",
            "\n"
          ]
        }
      ],
      "source": [
        "class DecisionTree:\n",
        "    def __init__(self, min_samples_split=2, max_depth=100,criterion='gini'):\n",
        "        self.min_samples_split = min_samples_split\n",
        "        self.max_depth =max_depth\n",
        "        self.criterion =criterion\n",
        "        self.root = None\n",
        "        self.feature_names = None\n",
        "\n",
        "    def _calculate_impurity(self, y):\n",
        "        if self.criterion == 'gini':\n",
        "            return self._gini_impurity(y)\n",
        "        elif self.criterion =='entropy':\n",
        "            return self._entropy(y)\n",
        "        else:\n",
        "            raise ValueError(\"Criterion must be 'gini' or 'entropy'\")\n",
        "\n",
        "    def _gini_impurity(self, y):\n",
        "        if len(y) == 0:\n",
        "            return 0\n",
        "        _, counts =np.unique(y, return_counts=True)\n",
        "        probabilities =counts/ len(y)\n",
        "        return 1 - np.sum(probabilities**2)\n",
        "\n",
        "    def _entropy(self, y):\n",
        "        if len(y) == 0:\n",
        "            return 0\n",
        "        _, counts = np.unique(y, return_counts=True)\n",
        "        probabilities = counts / len(y)\n",
        "        return -np.sum([p * np.log2(p) for p in probabilities if p > 0])\n",
        "\n",
        "    def _information_gain(self, parent, left_child, right_child):\n",
        "        weight_left = len(left_child) / len(parent)\n",
        "        weight_right = len(right_child) / len(parent)\n",
        "        gain = self._calculate_impurity(parent) - \\\n",
        "               (weight_left * self._calculate_impurity(left_child) +\n",
        "                weight_right * self._calculate_impurity(right_child))\n",
        "        return gain\n",
        "\n",
        "    def _find_best_split(self, X, y):\n",
        "        best_gain = -1\n",
        "        best_split = {}\n",
        "        n_samples, n_features =X.shape\n",
        "\n",
        "        for feature_index in range(n_features):\n",
        "            feature_values = X[:, feature_index]\n",
        "            possible_thresholds = np.unique(feature_values)\n",
        "\n",
        "            for threshold in possible_thresholds:\n",
        "                left_indices = np.where(feature_values <= threshold)[0]\n",
        "                right_indices = np.where(feature_values > threshold)[0]\n",
        "\n",
        "                if len(left_indices) > 0 and len(right_indices) > 0:\n",
        "                    y_left, y_right = y[left_indices], y[right_indices]\n",
        "                    gain = self._information_gain(y, y_left, y_right)\n",
        "\n",
        "                    if gain > best_gain:\n",
        "                        best_gain = gain\n",
        "                        best_split = {\n",
        "                            'feature_index': feature_index,\n",
        "                            'threshold': threshold,\n",
        "                            'left_indices': left_indices,\n",
        "                            'right_indices': right_indices\n",
        "                        }\n",
        "        return best_split\n",
        "\n",
        "    def _build_tree(self, X, y, depth=0):\n",
        "        n_samples, _ = X.shape\n",
        "        n_labels = len(np.unique(y))\n",
        "\n",
        "        # Pre-pruning stopping criteria\n",
        "        if (self.max_depth is not None and depth >= self.max_depth or\n",
        "            n_labels == 1 or\n",
        "            n_samples < self.min_samples_split):\n",
        "            leaf_value = self._most_common_label(y)\n",
        "            return Node(value=leaf_value, impurity=self._calculate_impurity(y))\n",
        "\n",
        "        best_split = self._find_best_split(X, y)\n",
        "\n",
        "        if not best_split:\n",
        "            leaf_value = self._most_common_label(y)\n",
        "            return Node(value=leaf_value, impurity=self._calculate_impurity(y))\n",
        "\n",
        "        left_indices, right_indices = best_split['left_indices'], best_split['right_indices']\n",
        "\n",
        "        left_subtree = self._build_tree(X[left_indices, :], y[left_indices], depth + 1)\n",
        "        right_subtree = self._build_tree(X[right_indices, :], y[right_indices], depth + 1)\n",
        "\n",
        "        return Node(best_split['feature_index'], best_split['threshold'],\n",
        "                    left_subtree, right_subtree, impurity=self._calculate_impurity(y))\n",
        "\n",
        "    def _most_common_label(self, y):\n",
        "        if len(y) == 0:\n",
        "            return None\n",
        "        counter = Counter(y)\n",
        "        return counter.most_common(1)[0][0]\n",
        "\n",
        "    def fit(self, X, y, feature_names=None):\n",
        "        self.feature_names = feature_names\n",
        "        self.root = self._build_tree(X, y)\n",
        "\n",
        "    def predict(self, X):\n",
        "        return np.array([self._traverse_tree(x, self.root) for x in X])\n",
        "\n",
        "    def _traverse_tree(self, x, node):\n",
        "        if node.value is not None:\n",
        "            return node.value\n",
        "\n",
        "        feature_value = x[node.feature_index]\n",
        "        if feature_value <= node.threshold:\n",
        "            return self._traverse_tree(x, node.left)\n",
        "        else:\n",
        "            return self._traverse_tree(x, node.right)\n",
        "\n",
        "    def print_tree(self, node=None, indent=\"  \", level=0):\n",
        "        if node is None:\n",
        "            node = self.root\n",
        "\n",
        "        if node.value is not None:\n",
        "            print(indent * level, \"Predict:\", node.value, f\"(Impurity: {node.impurity:.3f})\")\n",
        "        else:\n",
        "            feature_name = self.feature_names[node.feature_index] if self.feature_names else f\"Feature {node.feature_index}\"\n",
        "            print(indent * level, f\"If {feature_name} <= {node.threshold}: (Impurity: {node.impurity:.3f})\")\n",
        "            self.print_tree(node.left, indent, level + 1)\n",
        "            print(indent * level, f\"Else (If {feature_name} > {node.threshold}):\")\n",
        "            self.print_tree(node.right, indent, level + 1)\n",
        "\n",
        "print(\"Decision Tree Implementation Defined\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFmKc2OzGxfT"
      },
      "source": [
        "4. Post-Pruning (Reduced Error Pruning)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zqtdb6_lFeXz",
        "outputId": "3c047a69-fda8-4f0b-c4d5-c1beee231638"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Post-Pruning Implementation Defined.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def post_prune(tree, X_val, y_val):\n",
        "\n",
        "    pruned_tree = copy.deepcopy(tree)\n",
        "\n",
        "    y_pred_initial = pruned_tree.predict(X_val)\n",
        "    best_accuracy = accuracy_score(y_val, y_pred_initial)\n",
        "\n",
        "    while True:\n",
        "        current_best_prune_info = None\n",
        "\n",
        "        queue = [(pruned_tree.root, None, None)]\n",
        "        internal_nodes_with_parents = []\n",
        "        while queue:\n",
        "            current_node, parent, is_left = queue.pop(0)\n",
        "            if current_node.value is None:\n",
        "                internal_nodes_with_parents.append((current_node, parent, is_left))\n",
        "                if current_node.left:\n",
        "                    queue.append((current_node.left, current_node, True))\n",
        "                if current_node.right:\n",
        "                    queue.append((current_node.right, current_node, False))\n",
        "\n",
        "\n",
        "        for node, parent, is_left in reversed(internal_nodes_with_parents):\n",
        "            original_left, original_right = node.left, node.right\n",
        "            original_feature, original_threshold = node.feature_index, node.threshold\n",
        "\n",
        "\n",
        "            leaf_value_pred = Counter(pruned_tree.predict(X_train)).most_common(1)[0][0]\n",
        "            node.value = leaf_value_pred\n",
        "            node.left, node.right = None, None\n",
        "            node.feature_index, node.threshold = None, None\n",
        "\n",
        "            y_pred_pruned = pruned_tree.predict(X_val)\n",
        "            accuracy = accuracy_score(y_val, y_pred_pruned)\n",
        "\n",
        "\n",
        "            if accuracy >= best_accuracy:\n",
        "                best_accuracy = accuracy\n",
        "\n",
        "                current_best_prune_info = (node, parent, is_left, copy.deepcopy(node))\n",
        "\n",
        "\n",
        "            node.value = None\n",
        "            node.left, node.right = original_left, original_right\n",
        "            node.feature_index, node.threshold = original_feature, original_threshold\n",
        "\n",
        "\n",
        "        if current_best_prune_info:\n",
        "            node_to_prune, parent, is_left, new_leaf_node = current_best_prune_info\n",
        "\n",
        "            if parent is None:\n",
        "                 pruned_tree.root = new_leaf_node\n",
        "            elif is_left:\n",
        "                parent.left = new_leaf_node\n",
        "            else:\n",
        "                parent.right = new_leaf_node\n",
        "        else:\n",
        "            break\n",
        "\n",
        "    return pruned_tree\n",
        "\n",
        "print(\"Post-Pruning Implementation Defined.\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-TY8DVaHnAa"
      },
      "source": [
        "5. Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "IDMvcy4nFCvE"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, X_set, y_set, model_name=\"Model\"):\n",
        "    y_pred = model.predict(X_set)\n",
        "    accuracy = accuracy_score(y_set, y_pred)\n",
        "    precision, recall, f1, _ =precision_recall_fscore_support(y_set, y_pred,average='binary')\n",
        "    cm = confusion_matrix(y_set, y_pred)\n",
        "\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"Precision: {precision:.4f}\")\n",
        "    print(f\"Recall: {recall:.4f}\")\n",
        "    print(f\"F1-score: {f1:.4f}\")\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(cm)\n",
        "    print(\"-\" * 30 + \"\\n\")\n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFI4_tHOLSpc"
      },
      "source": [
        "6. Experiments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s4x7mChpH7N3",
        "outputId": "cdcf9ba9-0a65-491b-acc0-3f80e1115b79"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Experiment 1: Gini vs. Entropy (on Validation Set)\n",
            "Accuracy: 0.8445\n",
            "Precision: 0.7086\n",
            "Recall: 0.6328\n",
            "F1-score: 0.6686\n",
            "Confusion Matrix:\n",
            "[[6220  583]\n",
            " [ 823 1418]]\n",
            "------------------------------\n",
            "\n",
            "Accuracy: 0.8464\n",
            "Precision: 0.7696\n",
            "Recall: 0.5426\n",
            "F1-score: 0.6365\n",
            "Confusion Matrix:\n",
            "[[6439  364]\n",
            " [1025 1216]]\n",
            "------------------------------\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.8464175143741707"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(\"Experiment 1: Gini vs. Entropy (on Validation Set)\")\n",
        "gini_tree = DecisionTree(max_depth=10, criterion='gini')\n",
        "gini_tree.fit(X_train, y_train)\n",
        "evaluate_model(gini_tree, X_val, y_val,\"Gini Impurity Tree\")\n",
        "\n",
        "entropy_tree = DecisionTree(max_depth=10,criterion='entropy')\n",
        "entropy_tree.fit(X_train, y_train)\n",
        "evaluate_model(entropy_tree, X_val, y_val,\"Entropy Tree\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RX6zVB0qH7Kv",
        "outputId": "64a08638-9f8a-445e-a132-1c39a58c19c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Experiment 2: Effect of Max Depth (Pre-Pruning on Validation Set)\n",
            "Accuracy: 0.8205\n",
            "Precision: 0.7480\n",
            "Recall: 0.4159\n",
            "F1-score: 0.5346\n",
            "Confusion Matrix:\n",
            "[[6489  314]\n",
            " [1309  932]]\n",
            "------------------------------\n",
            "\n",
            "Accuracy: 0.8383\n",
            "Precision: 0.7551\n",
            "Recall: 0.5145\n",
            "F1-score: 0.6120\n",
            "Confusion Matrix:\n",
            "[[6429  374]\n",
            " [1088 1153]]\n",
            "------------------------------\n",
            "\n",
            "Accuracy: 0.8479\n",
            "Precision: 0.7729\n",
            "Recall: 0.5466\n",
            "F1-score: 0.6404\n",
            "Confusion Matrix:\n",
            "[[6443  360]\n",
            " [1016 1225]]\n",
            "------------------------------\n",
            "\n",
            "Accuracy: 0.8485\n",
            "Precision: 0.7776\n",
            "Recall: 0.5444\n",
            "F1-score: 0.6404\n",
            "Confusion Matrix:\n",
            "[[6454  349]\n",
            " [1021 1220]]\n",
            "------------------------------\n",
            "\n",
            "Accuracy: 0.8444\n",
            "Precision: 0.7083\n",
            "Recall: 0.6328\n",
            "F1-score: 0.6684\n",
            "Confusion Matrix:\n",
            "[[6219  584]\n",
            " [ 823 1418]]\n",
            "------------------------------\n",
            "\n",
            "Accuracy: 0.8046\n",
            "Precision: 0.6023\n",
            "Recall: 0.6225\n",
            "F1-score: 0.6122\n",
            "Confusion Matrix:\n",
            "[[5882  921]\n",
            " [ 846 1395]]\n",
            "------------------------------\n",
            "\n",
            "Best depth found: 8 with validation accuracy: 0.8485\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nExperiment 2: Effect of Max Depth (Pre-Pruning on Validation Set)\")\n",
        "depths = [2, 4, 6, 8, 10, None] # None means unlimited depth\n",
        "best_depth = -1\n",
        "best_val_accuracy = -1\n",
        "pre_pruned_tree = None\n",
        "\n",
        "for depth in depths:\n",
        "    current_depth_str = \"Unlimited\" if depth is None else str(depth)\n",
        "    tree = DecisionTree(max_depth=depth, min_samples_split=5, criterion='gini')\n",
        "    tree.fit(X_train, y_train)\n",
        "    val_accuracy = evaluate_model(tree, X_val, y_val, f\"Tree with Max Depth = {current_depth_str}\")\n",
        "    if val_accuracy > best_val_accuracy:\n",
        "        best_val_accuracy = val_accuracy\n",
        "        best_depth = depth\n",
        "        pre_pruned_tree = tree\n",
        "\n",
        "print(f\"Best depth found: {best_depth} with validation accuracy: {best_val_accuracy:.4f}\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 673
        },
        "id": "ATIs60LkH7Hp",
        "outputId": "06d5f1ba-d4de-4277-e9ad-32cbd38977da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Experiment 3: Comparing Pruning Methods (on Validation Set)\n",
            "Accuracy: 0.8035\n",
            "Precision: 0.5999\n",
            "Recall: 0.6216\n",
            "F1-score: 0.6106\n",
            "Confusion Matrix:\n",
            "[[5874  929]\n",
            " [ 848 1393]]\n",
            "------------------------------\n",
            "\n",
            "Accuracy: 0.8485\n",
            "Precision: 0.7776\n",
            "Recall: 0.5444\n",
            "F1-score: 0.6404\n",
            "Confusion Matrix:\n",
            "[[6454  349]\n",
            " [1021 1220]]\n",
            "------------------------------\n",
            "\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3779178799.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpre_pruned_tree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34mf\"Pre-Pruned Tree (Best Depth={best_depth})\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mpost_pruned_tree_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpost_prune\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_tree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpost_pruned_tree_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Post-Pruned Tree\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2333015643.py\u001b[0m in \u001b[0;36mpost_prune\u001b[0;34m(tree, X_val, y_val)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0mleaf_value_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpruned_tree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_common\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m             \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mleaf_value_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mright\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/collections/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, iterable, **kwds)\u001b[0m\n\u001b[1;32m    605\u001b[0m         '''\n\u001b[1;32m    606\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 607\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    608\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__missing__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/collections/__init__.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, iterable, **kwds)\u001b[0m\n\u001b[1;32m    697\u001b[0m                     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m                 \u001b[0m_count_elements\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "print(\"\\nExperiment 3: Comparing Pruning Methods (on Validation Set)\")\n",
        "full_tree = DecisionTree(criterion='gini', max_depth=100)\n",
        "full_tree.fit(X_train, y_train, feature_names=X.columns)\n",
        "evaluate_model(full_tree, X_val,y_val, \"Full (Unpruned) Tree\")\n",
        "\n",
        "evaluate_model(pre_pruned_tree, X_val, y_val,f\"Pre-Pruned Tree (Best Depth={best_depth})\")\n",
        "post_pruned_tree_model = post_prune(full_tree, X_val, y_val)\n",
        "evaluate_model(post_pruned_tree_model, X_val, y_val, \"Post-Pruned Tree\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GNfh2k8oaAH_",
        "outputId": "6a53c518-7154-4fff-fbf9-8332f3504f0e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Final Evaluation on Test Set\n",
            "Choosing the Pre-Pruned Tree as the best model based on validation performance.\n",
            "Accuracy: 0.8489\n",
            "Precision: 0.7888\n",
            "Recall: 0.5330\n",
            "F1-score: 0.6361\n",
            "Confusion Matrix:\n",
            "[[6483  320]\n",
            " [1047 1195]]\n",
            "------------------------------\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.8488667772249862"
            ]
          },
          "execution_count": 68,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(\"\\nFinal Evaluation on Test Set\")\n",
        "print(\"Choosing the Pre-Pruned Tree as the best model based on validation performance.\")\n",
        "evaluate_model(pre_pruned_tree, X_test, y_test, \"Final Model (Pre-Pruned Scratch)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t32mxytveWcr",
        "outputId": "d6e6eb29-8c2c-4d2d-8771-8702c7aab2c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Comparison with Scikit-learn\n",
            "Accuracy: 0.8494\n",
            "Precision: 0.7902\n",
            "Recall: 0.5343\n",
            "F1-score: 0.6376\n",
            "Confusion Matrix:\n",
            "[[6485  318]\n",
            " [1044 1198]]\n",
            "------------------------------\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.8494195688225539"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(\"\\nComparison with Scikit-learn\")\n",
        "sklearn_tree = SklearnDecisionTree(criterion='gini', max_depth=best_depth, min_samples_split=5,random_state=42)\n",
        "sklearn_tree.fit(X_train, y_train)\n",
        "evaluate_model(sklearn_tree, X_test, y_test, \"Scikit-learn Decision Tree\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "SEkQoobeeWVK",
        "outputId": "23787382-0e55-4ff9-ae05-fe4ed47c2040"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Top Features from Scratch Implementation\n",
            "The most important features are those used for splits at the top of the tree.\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "The truth value of a Index is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3131904014.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nTop Features from Scratch Implementation\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The most important features are those used for splits at the top of the tree.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mfull_tree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-2321284698.py\u001b[0m in \u001b[0;36mprint_tree\u001b[0;34m(self, node, indent, level)\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindent\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Predict:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"(Impurity: {node.impurity:.3f})\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m             \u001b[0mfeature_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_index\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_names\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34mf\"Feature {node.feature_index}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindent\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"If {feature_name} <= {node.threshold}: (Impurity: {node.impurity:.3f})\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m__nonzero__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3188\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3189\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__nonzero__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mNoReturn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3190\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m   3191\u001b[0m             \u001b[0;34mf\"The truth value of a {type(self).__name__} is ambiguous. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3192\u001b[0m             \u001b[0;34m\"Use a.empty, a.bool(), a.item(), a.any() or a.all().\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: The truth value of a Index is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all()."
          ]
        }
      ],
      "source": [
        "print(\"\\nTop Features from Scratch Implementation\")\n",
        "print(\"The most important features are those used for splits at the top of the tree.\")\n",
        "full_tree.print_tree(level=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zVFwuAkeHrI-"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
